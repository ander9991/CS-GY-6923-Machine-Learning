{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree with Adaboost Tutorial: UCI Lymphography Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, the decision tree as demonstrated in the previous assignment will be enhanced by a boosting algorithm -- in this case, Adaboost. \n",
    "\n",
    "The following will be demonstrated and can be used as a supplement with Assignment 7.\n",
    " * Loading a dataset from its URL\n",
    " * Splitting a dataset in a training and testing set\n",
    " * Creating a decision tree object\n",
    " * Creating an Adaboost classifier object\n",
    " * Tuning a decision tree model with Adaboost with Sklearn's grid search option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous tutorials, the dataset may have been downloaded onto your local machine or it was part of the dataset package in Sklearn. Here, using the read_csv function from Pandas, we may retrieve a dataset this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/lymphography/lymphography.data',\n",
    "                           sep= ',',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the first five entries of this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Samples:: \", df.shape[0])\n",
    "print(\"Number of features: \", df.shape[1]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating X and y matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataframe created, the data matrix X and target matrix y may be created as follows. From the description of the dataset available online, the first column is the ground truth (target) while the rest of the data are attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.values[:, 1:]\n",
    "y = df.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a training and testing set, we can use Sklearn's built-in function. The test_size parameter allows us to vary the percentage of data to be allocated as training data and testing data. In this case, we are creating a 70:30 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similiar to the previous assignment, the decision tree can be built using DecisionTreeClassifier. After building it with the desired parameters, we will fit it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a decision tree object\n",
    "tree_gini = DecisionTreeClassifier()\n",
    "\n",
    "# Fit on training data\n",
    "tree_gini.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Adaboost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Adaboost classifier can be built with another built-in function AdaBoostClassifier. Note that for the base estimator of the classifier, we are passing in the decision tree we have previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(base_estimator=tree_gini)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response with test dataset\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Decision Tree with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can to tune decision tree either can hand or by Sklearn's grid search option to yield a higher accuracy. In grid search, we provide lists of which contain ranges of each parameter in the decision tree. In return, the combination of parameters that will yield the highest accuracy will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_param = {'criterion':['gini','entropy'],\n",
    "             'max_depth':[4,5,6,7,8,9,10,11,12,15,20],\n",
    "             'min_samples_split':[20,30,40,50,60,70,80,90,100], \n",
    "             'min_samples_leaf':[5,6,7,8,9,10], \n",
    "             'max_features':list(range(1,X_train.shape[1])), \n",
    "             'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'presort':[True, False]\n",
    "            }\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), tree_param, cv=5)\n",
    "grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now knowing the parameters that will yield the highest accuracy provided in tree_param, we can edit our decision tree and rerun it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = grid.best_estimator_\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=100,\n",
    "                         learning_rate=1,\n",
    "                         random_state=8,\n",
    "                         base_estimator=tree)\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
